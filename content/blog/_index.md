---
title: Web Crawling

---
#### Required Understanding:

##### What is crawling?

Information made available on web pages tends to be wonderfully laid out for a user via the user interface (UI)/ graphical user interface (GUI). What looks organized and intuitive for people, however, is rarely that for computers & databases. Web crawling, or scraping, is the act of pulling information from a uniform resource locater (aka, a URL or web address). Anytime an entity loads a page in their browser, all of the information that is visible on the site is data that can be pulled down, or mined. 

##### Why crawl?

By crawling, one is able to structure the information (think of a taking a jpeg and putting it into a spreadsheet), which allows for transformations, aggregations, and overall deeper review than what the url might offer its intended users. Moreover, once the information has been structured, one can store that historical information allowing the usage of data that may no longer be visible to users later in time. If one is the only entity tracking, or is better situated to analyze and review historical data, they will have a distinct advantage on decision making.

##### Are there limitations to crawling?

Generally speaking, crawling is rather common, but there are some restrictions. Only data that is deemed `publicly available`, and if you are curious what that really means, just review a site for a terms of service (ToS). If something like this appears: ![](file:///Users/chris.pachulski/Desktop/Screen%20Shot%202022-12-29%20at%202.34.19%20PM.png)